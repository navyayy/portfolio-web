---
title: "Deepfake AI"
excerpt: "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus."
coverImage: "/assets/blog/preview/cover.jpg"
date: "2020-03-16T05:35:07.322Z"
author:
  name: Navya Srivastav
  picture: "/assets/blog/authors/navyayy.png"
ogImage:
  url: "/assets/blog/preview/cover.jpg"
---

## Deepfake AI

One method of altering photos is through deep fakes. The practice of manipulating images is not new. Artificial Intelligence is the fundamental technology used today to produce deepfakes. Improved capabilities are provided by AI-supported deepfake technology, but there is also a greater potential for manipulation and bad actor intervention.

By manipulating photos, videos, or sounds with the use of artificial intelligence (AI) and machine learning, deepfakes are produced that make it difficult to distinguish fact from fiction. Despite their obvious advantages in criminal investigations, filmmaking, education, and artistic expression, they may also be used to manipulate elections, take advantage of people, and disseminate false information widely. Although editing programs such as Photoshop have been around for decades, the first known application of deepfake technology is said to have come from a Reddit user who, in 2017, used an openly available AI-powered program to create pornographic content by superimposing the faces of celebrities on the bodies of regular people.

Nowadays, audio-visual recordings and images may be easily morphed by untrained and semi-skilled folks to create deepfakes. A consortium of stakeholders from the industry and civic society, the Deeptrust Alliance, issued a warning in 2020, saying that "the tools to create and disseminate disinformation are easier, faster, cheaper, and more accessible than ever."
More and more experts are examining fake news and developing tools to detect deepfakes. Large tech companies including Microsoft, Google, and Meta have publicly denounced deepfake technology and are developing instruments to identify it. To combat false information, Microsoft is developing new anti-deepfake technology (Microsoft Video Authenticator). Google-owned YouTube reaffirmed in February 2020 that it will not post deepfake anything about the 2020 US census, voting processes, or election.

The use of deepfakes to perpetrate technology-facilitated online gendered violence has been a rising concern. A 2019 study conducted by AI firm Deeptrace found that a staggering 96% of deepfakes were pornographic, and 99% of them involved women.

Deepfakes and related technologies are becoming more difficult to identify, but there are now more tools available to protect people from abusing them. The Massachusetts Institute of Technology (MIT), for example, developed the Detect Fakes website to assist users in spotting deepfakes by emphasizing minute, minute features.
